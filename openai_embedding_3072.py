#!/usr/bin/env python3
"""
OpenAI text-embedding-3-large (3072æ¬¡å…ƒ) å¯¾å¿œåŸ‹ã‚è¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ 
Claude APIå‡ºåŠ›ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨Supabaseé€£æº
"""

import os
import openai
import psycopg2
import numpy as np
from typing import List, Dict, Any, Optional
import json
import logging
from datetime import datetime
from dataclasses import dataclass

@dataclass
class OpenAIEmbeddingConfig:
    """OpenAI Embeddingè¨­å®š"""
    model_name: str = "text-embedding-3-large"
    embedding_dimensions: int = 3072
    max_tokens: int = 8192  # text-embedding-3-large ã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
    batch_size: int = 100   # APIåˆ¶é™ã«å¿œã˜ã¦èª¿æ•´
    api_key: str = ""

@dataclass
class DatabaseConfig:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š"""
    host: str = "localhost"
    port: int = 5432
    database: str = "postgres"
    user: str = "postgres"
    password: str = ""

class OpenAIEmbeddingProcessor:
    """OpenAI Embeddingå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: OpenAIEmbeddingConfig):
        self.config = config
        self.logger = self._setup_logger()
        self.client = self._setup_openai_client()
        
    def _setup_logger(self) -> logging.Logger:
        logger = logging.getLogger("openai_embedding_processor")
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger
    
    def _setup_openai_client(self):
        """OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š"""
        api_key = self.config.api_key or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OpenAI API key is required")
        
        openai.api_key = api_key
        self.logger.info(f"âœ… OpenAI client initialized with model: {self.config.model_name}")
        return openai
    
    def generate_embeddings(
        self, 
        texts: List[str],
        user_id: Optional[str] = None
    ) -> List[List[float]]:
        """ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        
        if not texts:
            return []
        
        self.logger.info(f"ğŸ”¢ Generating {self.config.embedding_dimensions}D embeddings for {len(texts)} texts")
        
        try:
            # ãƒãƒƒãƒå‡¦ç†
            all_embeddings = []
            
            for i in range(0, len(texts), self.config.batch_size):
                batch_texts = texts[i:i + self.config.batch_size]
                
                self.logger.info(f"  Processing batch {i//self.config.batch_size + 1}/{(len(texts)-1)//self.config.batch_size + 1}")
                
                response = openai.Embedding.create(
                    model=self.config.model_name,
                    input=batch_texts,
                    encoding_format="float",
                    user=user_id  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ç”¨
                )
                
                batch_embeddings = [item['embedding'] for item in response['data']]
                all_embeddings.extend(batch_embeddings)
                
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                if len(texts) > self.config.batch_size:
                    import time
                    time.sleep(0.1)
            
            # æ¬¡å…ƒæ•°æ¤œè¨¼
            if all_embeddings and len(all_embeddings[0]) != self.config.embedding_dimensions:
                raise ValueError(
                    f"Expected {self.config.embedding_dimensions} dimensions, "
                    f"got {len(all_embeddings[0])}"
                )
            
            self.logger.info(f"âœ… Generated {len(all_embeddings)} embeddings successfully")
            return all_embeddings
            
        except Exception as e:
            self.logger.error(f"âŒ Embedding generation failed: {e}")
            raise
    
    def generate_single_embedding(self, text: str, user_id: Optional[str] = None) -> List[float]:
        """å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        embeddings = self.generate_embeddings([text], user_id)
        return embeddings[0] if embeddings else []

class DesignEmbeddingManager:
    """design_embeddings ãƒ†ãƒ¼ãƒ–ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_config: DatabaseConfig, embedding_processor: OpenAIEmbeddingProcessor):
        self.db_config = db_config
        self.embedding_processor = embedding_processor
        self.logger = embedding_processor.logger
        
    def get_db_connection(self):
        """PostgreSQLæ¥ç¶š"""
        try:
            conn = psycopg2.connect(
                host=self.db_config.host,
                port=self.db_config.port,
                database=self.db_config.database,
                user=self.db_config.user,
                password=self.db_config.password
            )
            return conn
        except Exception as e:
            self.logger.error(f"âŒ Database connection failed: {e}")
            raise
    
    def save_design_embedding(
        self,
        example_id: str,
        text_content: str,
        embedding_type: str = "claude_output",
        metadata: Dict[str, Any] = None
    ) -> str:
        """design_embeddingsãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        
        try:
            # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            embedding = self.embedding_processor.generate_single_embedding(text_content)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    insert_query = """
                    INSERT INTO design_embeddings (
                        example_id, embedding, embedding_type, text_content, 
                        model_name, embedding_dimensions, metadata, created_at
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s
                    ) RETURNING id;
                    """
                    
                    cur.execute(insert_query, (
                        example_id,
                        embedding,  # vectorå‹ã¨ã—ã¦ä¿å­˜
                        embedding_type,
                        text_content,
                        self.embedding_processor.config.model_name,
                        self.embedding_processor.config.embedding_dimensions,
                        json.dumps(metadata or {}),
                        datetime.now()
                    ))
                    
                    embedding_id = cur.fetchone()[0]
                    conn.commit()
            
            self.logger.info(f"âœ… Design embedding saved with ID: {embedding_id}")
            return embedding_id
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to save design embedding: {e}")
            raise
    
    def search_similar_embeddings(
        self,
        query_text: str,
        limit: int = 5,
        similarity_threshold: float = 0.7,
        example_id_filter: List[str] = None
    ) -> List[Dict[str, Any]]:
        """é¡ä¼¼åŸ‹ã‚è¾¼ã¿æ¤œç´¢"""
        
        try:
            # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            query_embedding = self.embedding_processor.generate_single_embedding(query_text)
            
            # é¡ä¼¼åº¦æ¤œç´¢
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    base_query = """
                    SELECT 
                        de.id,
                        de.example_id,
                        de.embedding_type,
                        de.text_content,
                        de.metadata,
                        de.created_at,
                        (1 - (de.embedding <=> %s))::float AS similarity
                    FROM design_embeddings de
                    WHERE (1 - (de.embedding <=> %s)) > %s
                    """
                    
                    params = [query_embedding, query_embedding, similarity_threshold]
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶è¿½åŠ 
                    if example_id_filter:
                        placeholders = ','.join(['%s'] * len(example_id_filter))
                        base_query += f" AND de.example_id IN ({placeholders})"
                        params.extend(example_id_filter)
                    
                    base_query += " ORDER BY similarity DESC LIMIT %s"
                    params.append(limit)
                    
                    cur.execute(base_query, params)
                    results = cur.fetchall()
                    
                    # çµæœã®æ•´å½¢
                    columns = [desc[0] for desc in cur.description]
                    search_results = []
                    
                    for row in results:
                        result_dict = dict(zip(columns, row))
                        
                        # metadata ã® JSON ãƒ‘ãƒ¼ã‚¹
                        if result_dict.get('metadata'):
                            try:
                                result_dict['metadata'] = json.loads(result_dict['metadata'])
                            except json.JSONDecodeError:
                                result_dict['metadata'] = {}
                        
                        search_results.append(result_dict)
            
            self.logger.info(f"ğŸ” Found {len(search_results)} similar embeddings")
            return search_results
            
        except Exception as e:
            self.logger.error(f"âŒ Similar embedding search failed: {e}")
            raise

class ClaudeOutputProcessor:
    """Claude APIå‡ºåŠ›å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, embedding_manager: DesignEmbeddingManager):
        self.embedding_manager = embedding_manager
        self.logger = embedding_manager.logger
    
    def process_claude_response(
        self,
        claude_response: Dict[str, Any],
        figma_url: str,
        example_id: str
    ) -> Dict[str, Any]:
        """Claude API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å‡¦ç†ã¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–"""
        
        self.logger.info(f"ğŸ“ Processing Claude response for example_id: {example_id}")
        
        try:
            # Claudeå‡ºåŠ›ã‹ã‚‰ä¸»è¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            main_content = self._extract_main_content(claude_response)
            
            # åˆ†é¡çµæœã¨ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
            genre_classification = self._extract_genre(claude_response)
            design_scores = self._extract_scores(claude_response)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
            metadata = {
                "figma_url": figma_url,
                "genre": genre_classification,
                "scores": design_scores,
                "processing_timestamp": datetime.now().isoformat(),
                "original_response": claude_response
            }
            
            # å„ç¨®ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            embeddings_created = []
            
            # 1. ãƒ¡ã‚¤ãƒ³å‡ºåŠ›ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            main_embedding_id = self.embedding_manager.save_design_embedding(
                example_id=example_id,
                text_content=main_content,
                embedding_type="claude_main_output",
                metadata=metadata
            )
            embeddings_created.append(("main_output", main_embedding_id))
            
            # 2. ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            if genre_classification:
                genre_embedding_id = self.embedding_manager.save_design_embedding(
                    example_id=example_id,
                    text_content=f"UI genre: {genre_classification}",
                    embedding_type="genre_classification",
                    metadata={"genre": genre_classification, "figma_url": figma_url}
                )
                embeddings_created.append(("genre", genre_embedding_id))
            
            # 3. ã‚¹ã‚³ã‚¢è©³ç´°ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            if design_scores:
                scores_text = self._format_scores_as_text(design_scores)
                scores_embedding_id = self.embedding_manager.save_design_embedding(
                    example_id=example_id,
                    text_content=scores_text,
                    embedding_type="design_scores",
                    metadata={"scores": design_scores, "figma_url": figma_url}
                )
                embeddings_created.append(("scores", scores_embedding_id))
            
            result = {
                "example_id": example_id,
                "figma_url": figma_url,
                "genre": genre_classification,
                "design_scores": design_scores,
                "embeddings_created": embeddings_created,
                "main_content": main_content,
                "metadata": metadata
            }
            
            self.logger.info(f"âœ… Created {len(embeddings_created)} embeddings for example {example_id}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to process Claude response: {e}")
            raise
    
    def _extract_main_content(self, claude_response: Dict[str, Any]) -> str:
        """Claude ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º"""
        
        # Claude API ã®ä¸€èˆ¬çš„ãªå¿œç­”å½¢å¼ã«å¯¾å¿œ
        if 'content' in claude_response:
            if isinstance(claude_response['content'], list):
                # Claude æ–°å½¢å¼
                text_parts = []
                for content_block in claude_response['content']:
                    if content_block.get('type') == 'text':
                        text_parts.append(content_block.get('text', ''))
                return '\n'.join(text_parts)
            else:
                # ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—å½¢å¼
                return str(claude_response['content'])
        
        # ãã®ä»–ã®å½¢å¼
        return str(claude_response.get('text', str(claude_response)))
    
    def _extract_genre(self, claude_response: Dict[str, Any]) -> Optional[str]:
        """ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ã®æŠ½å‡º"""
        
        content = self._extract_main_content(claude_response)
        
        # ã‚ˆãã‚ã‚‹ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        genre_patterns = {
            "ãƒãƒ£ãƒƒãƒˆUI": ["chat", "message", "ãƒãƒ£ãƒƒãƒˆ", "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"],
            "äºˆç´„ç”»é¢": ["booking", "reservation", "äºˆç´„", "ã‚¢ãƒã‚¤ãƒ³ãƒˆ"],
            "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰": ["dashboard", "analytics", "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "åˆ†æ"],
            "ãƒ•ã‚©ãƒ¼ãƒ ": ["form", "input", "ãƒ•ã‚©ãƒ¼ãƒ ", "å…¥åŠ›"],
            "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³": ["navigation", "menu", "nav", "ãƒŠãƒ“", "ãƒ¡ãƒ‹ãƒ¥ãƒ¼"],
            "ã‚«ãƒ¼ãƒ‰": ["card", "item", "ã‚«ãƒ¼ãƒ‰", "ã‚¢ã‚¤ãƒ†ãƒ "],
            "ãƒ¢ãƒ¼ãƒ€ãƒ«": ["modal", "dialog", "popup", "ãƒ¢ãƒ¼ãƒ€ãƒ«", "ãƒ€ã‚¤ã‚¢ãƒ­ã‚°"],
            "ãƒªã‚¹ãƒˆ": ["list", "table", "grid", "ãƒªã‚¹ãƒˆ", "ãƒ†ãƒ¼ãƒ–ãƒ«"],
        }
        
        content_lower = content.lower()
        
        for genre, keywords in genre_patterns.items():
            if any(keyword in content_lower for keyword in keywords):
                return genre
        
        return "ãã®ä»–"
    
    def _extract_scores(self, claude_response: Dict[str, Any]) -> Dict[str, float]:
        """ãƒ‡ã‚¶ã‚¤ãƒ³ã‚¹ã‚³ã‚¢ã®æŠ½å‡º"""
        
        content = self._extract_main_content(claude_response)
        scores = {}
        
        # ã‚¹ã‚³ã‚¢æŠ½å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ï¼‰
        import re
        
        score_patterns = {
            "é…è‰²": [r"é…è‰²[ï¼š:]\s*([0-9.]+)", r"color[ï¼š:]\s*([0-9.]+)"],
            "ä¸€è²«æ€§": [r"ä¸€è²«æ€§[ï¼š:]\s*([0-9.]+)", r"consistency[ï¼š:]\s*([0-9.]+)"],
            "ãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼": [r"ãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼[ï¼š:]\s*([0-9.]+)", r"hierarchy[ï¼š:]\s*([0-9.]+)"],
            "ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£": [r"ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£[ï¼š:]\s*([0-9.]+)", r"usability[ï¼š:]\s*([0-9.]+)"],
            "ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–": [r"ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–[ï¼š:]\s*([0-9.]+)", r"responsive[ï¼š:]\s*([0-9.]+)"],
            "ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£": [r"ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£[ï¼š:]\s*([0-9.]+)", r"accessibility[ï¼š:]\s*([0-9.]+)"]
        }
        
        for score_name, patterns in score_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, content, re.IGNORECASE)
                if match:
                    try:
                        score_value = float(match.group(1))
                        # 0-10ã‚¹ã‚±ãƒ¼ãƒ«ã‚’0-1ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–
                        if score_value > 1.0:
                            score_value = score_value / 10.0
                        scores[score_name] = score_value
                        break
                    except ValueError:
                        continue
        
        return scores
    
    def _format_scores_as_text(self, scores: Dict[str, float]) -> str:
        """ã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        if not scores:
            return ""
        
        score_texts = []
        for category, score in scores.items():
            score_texts.append(f"{category}: {score:.2f}")
        
        return f"Design scores - {', '.join(score_texts)}"

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã¨ãƒ†ã‚¹ãƒˆ"""
    
    # è¨­å®š
    openai_config = OpenAIEmbeddingConfig(
        api_key=os.getenv("OPENAI_API_KEY", "")
    )
    db_config = DatabaseConfig(
        password=os.getenv("POSTGRES_PASSWORD", "")
    )
    
    # åˆæœŸåŒ–
    embedding_processor = OpenAIEmbeddingProcessor(openai_config)
    embedding_manager = DesignEmbeddingManager(db_config, embedding_processor)
    claude_processor = ClaudeOutputProcessor(embedding_manager)
    
    # ãƒ†ã‚¹ãƒˆç”¨Claudeå¿œç­”
    sample_claude_response = {
        "content": """
        ã“ã®Figmaãƒ‡ã‚¶ã‚¤ãƒ³ã¯ã€ãƒãƒ£ãƒƒãƒˆUIã€‘ã®ã‚¸ãƒ£ãƒ³ãƒ«ã«åˆ†é¡ã•ã‚Œã¾ã™ã€‚
        
        è©•ä¾¡ã‚¹ã‚³ã‚¢:
        - é…è‰²: 8.5
        - ä¸€è²«æ€§: 9.0
        - ãƒ’ã‚¨ãƒ©ãƒ«ã‚­ãƒ¼: 7.5
        - ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£: 8.0
        - ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£: 6.5
        
        å…¨ä½“çš„ã«ãƒ¢ãƒ€ãƒ³ã§ä½¿ã„ã‚„ã™ã„ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®éšå±¤æ§‹é€ ãŒæ˜ç¢ºã§ã€ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚‚çµ±ä¸€ã•ã‚Œã¦ã„ã¾ã™ã€‚
        """
    }
    
    # å‡¦ç†ãƒ†ã‚¹ãƒˆ
    try:
        result = claude_processor.process_claude_response(
            claude_response=sample_claude_response,
            figma_url="https://figma.com/test-chat-ui",
            example_id="test-example-001"
        )
        
        print("âœ… Processing successful:")
        print(f"  Genre: {result['genre']}")
        print(f"  Scores: {result['design_scores']}")
        print(f"  Embeddings created: {len(result['embeddings_created'])}")
        
        # é¡ä¼¼æ¤œç´¢ãƒ†ã‚¹ãƒˆ
        similar_results = embedding_manager.search_similar_embeddings(
            query_text="ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ãƒ‡ã‚¶ã‚¤ãƒ³",
            limit=3
        )
        
        print(f"\nğŸ” Similar embeddings found: {len(similar_results)}")
        for result in similar_results:
            print(f"  - Similarity: {result['similarity']:.3f}, Type: {result['embedding_type']}")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")

if __name__ == "__main__":
    main()